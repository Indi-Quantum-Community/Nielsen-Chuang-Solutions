\paragraph{2.34} \textbf{Square Root and Log of a Matrix}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\\

Given $A = \begin{bmatrix}
    4 & 3 \\ 3 & 4
\end{bmatrix}$

We need to find the eigen values and the eigen vectors, i.e
$$ \text{det } (A -\lambda I) = (4 - \lambda)^2 - 3^2$$
$$ = \lambda^2 - 8 \lambda + 7$$
$$ (\lambda -1) (\lambda - 7)$$

The eigenvalues for the $A$ matrix are $ \lambda = 1, 7$. Corresponding eigenvectors are :

$|\lambda = 1\rangle = \frac{1}{\sqrt{2}}\begin{bmatrix}
    1 \\ -1
\end{bmatrix} $ and 
$|\lambda = 7\rangle = \frac{1}{\sqrt{2}}\begin{bmatrix}
    1 \\ 1
\end{bmatrix} $ 

Thus the $A$ matrix can be written as :
$$ A = 1|\lambda = 1\rangle \langle \lambda = 1| + 7|\lambda=7\rangle \langle \lambda =7|$$

Now, it's easier to apply the operations, hence:
$$ \sqrt{A} = \sqrt{1}|\lambda = 1\rangle \langle \lambda = 1|+ \sqrt{7}|\lambda=7\rangle \langle \lambda =7|$$

$$ = \frac{1}{2} \begin{bmatrix}
    1 & -1 \\ -1 & 1
\end{bmatrix}  + \frac{\sqrt{7}}{2} \begin{bmatrix}
    1 & 1 \\ 1 & 1
\end{bmatrix}$$

$$ = \frac{1}{2} \begin{bmatrix}
    1 + \sqrt{7} & -1+\sqrt{7} \\
    -1 + \sqrt{7} & 1 + \sqrt{7}
\end{bmatrix}$$

Similarly for logarithm,

$$ \log(A) = \log( 1)\rangle \langle \lambda = 1| + \log(7)|\lambda=7\rangle \langle \lambda =7|$$

$$ = \frac{\log(7)}{2} \begin{bmatrix}
    1 & 1 \\ 1 & 1
\end{bmatrix}$$

\paragraph{2.35} \textbf{Exponent of Pauli Matrices}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\\

We know :
$$ \vec{v} \cdot \Vec{\sigma} = \sum_{i = 1}^3 v_i \sigma_i$$

where $\sigma_i$ is the $i^{th}$ Pauli Matrix.

$$ = v_1 \begin{bmatrix}
    0 & 1 \\ 1 & 0 
\end{bmatrix} +   v_2 \begin{bmatrix}
    0 & -\iota \\ \iota & 0 
\end{bmatrix}  + v_3 \begin{bmatrix}
    1 & 0 \\ 0 & -1 
\end{bmatrix}$$

$$ = \begin{bmatrix}
    v_3 & v_1 - \iota v_2 \\ v_1 + \iota v_2 & -v_3
\end{bmatrix}$$

Now, for the eigen values:

$$ \text{det }(\vec{v} \cdot \vec{\sigma} - \lambda I)  = (v_3 - \lambda) (-v_3 \lambda) - (v_1 - \iota v_2) (v_1 + \iota v_2)$$

$$ \lambda^2 - (v_1^2 + v_2^2 + v_3^2)$$
$$ = \lambda^2 - 1 \ ( \text{ Since }|\vec{v}| = 1)$$

Eigenvalues are $\lambda = \pm 1$. We let the eigenvectors be $|\lambda_{\pm 1} \rangle$ with the eigen values $\pm 1$.

We know that $\vec{v} \cdot \vec{\sigma}$  is Hermitian, and hence diagonalizable. Then

$$ \vec{v} \cdot \vec{\sigma}   = |\lambda_1\rangle \langle \lambda_1| - |\lambda_{-1}\rangle \langle \lambda_{-1}|$$

Thus:
$$ \exp{\iota \theta \vec{v} \cdot \vec{\sigma}} = \exp{\iota \theta} |\lambda_1\rangle \langle \lambda_1| + \exp{-\iota \theta} |\lambda_{-1} \rangle \langle \lambda_{-1}|$$
$$ = (\cos{\theta} + \iota \sin{\theta}) |\lambda_1\rangle \langle \lambda_1| + (\cos{\theta} - \iota \sin{\theta}) |\lambda_{-1} \rangle \langle \lambda_{-1}| $$

$$ = \cos{\theta}|\lambda_1\rangle \langle \lambda_1| +  |\lambda_{-1} \rangle \langle \lambda_{-1}| + \iota \sin{\theta} |\lambda_1\rangle \langle \lambda_1| -  |\lambda_{-1} \rangle \langle \lambda_{-1}|  $$

$$ = \cos{\theta} I + \iota \sin{\theta} \vec{v} \cdot \vec{\sigma}$$

Since $\vec{v}\cdot \vec{\sigma}$ is Hermitian, $|\lambda_1\rangle$ and $|\lambda_{-1}\rangle$ are orthogonal. Thus

$$ |\lambda_1 \rangle \langle \lambda_1| + |\lambda_{-1}\rangle \langle \lambda_{-1}| = I$$

\paragraph{2.36} \textbf{Pauli Matrices except $I$ has a trace $0$}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\\
For $\sigma_1$:
$$ \text{Tr}(\sigma_1) = \text{Tr}\bigg( \begin{bmatrix}
    0 & 1 \\ 1 & 0 
\end{bmatrix} \bigg) = 0 $$

For $\sigma_2$
$$ \text{Tr}(\sigma_2) = \text{Tr}\bigg( \begin{bmatrix}
    0 & -\iota \\ \iota & 0 
\end{bmatrix} \bigg) = 0 $$


For $\sigma_3$
$$ \text{Tr}(\sigma_3) = \text{Tr}\bigg( \begin{bmatrix}
    1 & 0 \\ 0 & -1 
\end{bmatrix} \bigg) = 0 $$


\paragraph{2.37} \textbf{Cyclic Properties of Trace}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\\

$$ \text{Tr} (AB) = \sum_i \langle i |AB|i\rangle$$
$$ = \sum_i \langle i |AIB|i\rangle$$
$$  = \sum_i \langle i |A|j\rangle \langle j|B|i\rangle$$
$$  = \sum_i \langle j |B|i\rangle \langle i|A|j\rangle$$
$$ = \sum_j \langle j | BA | j \rangle$$

$$ \text{Tr}(BA)$$

\paragraph{2.38} \textbf{Linearity of Trace}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\\
$$ \text{Tr}(A+B) = \sum_i \langle i | A+B|i \rangle$$
$$ = \sum_i \langle i | A| i \rangle +\langle i|B|i \rangle$$
$$ = \sum_i \langle i | A| i \rangle +\sum_i \langle i|B|i \rangle$$
$$ = \text{Tr}(A) + \text{Tr}(B)$$

$$ \text{Tr}(zA) = \sum_i \langle i | zA | i\rangle$$
$$ \sum_i z \langle i |A|i\rangle$$
$$ = z \sum_{i} \langle i |A|i\rangle$$
$$ = z\text{Tr}(A)$$

\paragraph{2.39} \textbf{Hilbert-Schmidt Inner Product on Operators}%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\\

We have to show $$ (A,B) = \text{Tr}(A^{\dagger} B)$$

$$\bigg( A, \sum_i \lambda_i B_i \bigg) = \text{ Tr } \bigg[ A^{\dagger} \bigg(\sum_i \lamda_i B_i \bigg)\bigg]$$
$$ = \text{Tr}(A^{\dagger} \lambda_1 B_1)+ . . . + \text{Tr}(A^{\dagger} \lambda_n B_n)$$

$$ \lambda_1 \text{Tr}(A^{\dagger} B_1) + .. + \lambda_n \text{Tr}(A^{\dagger} B_n)$$

$$ \sum_{i} \lambda_i \text{Tr}(A^{\dagger} B_i)$$

and for
$$ (A,B)^* = \bigg(\text{Tr}(A^{\dagger}B)\bigg)^*$$

$$ = \bigg( \sum_{i,j} \langle i |A^{\dagger} | j\rangle \langle j |B|i\rangle \bigg)^*$$
$$ =\sum_{i,j} \langle i |A^{\dagger}|j\rangle^* \langle j |B |i\rangle^*$$
$$ =  \sum_{i,j} \langle j |B|i\rangle^* \langle i |A^{\dagger} |j\rangle^* $$
$$ =  \sum_{i,j} \langle i |B^{\dagger}|j\rangle \langle j |A |i\rangle$$
$$ =  \sum_{i,j} \langle i |B^{\dagger} A|i\rangle$$
$$ \text{Tr}(B^{\dagger}A)$$
$$ = (B,A)$$

and,
$$ (A,A) = \text{Tr}(A^{\dagger} A)$$
$$ = \sum_i \langle i |A^{\dagger} A | i\rangle$$

Since $A^{\dagger}A$ is positive, $\langle i |A^{\dagger}A|i\rangle \ge 0 \ \forall \ |i\rangle$
Let $a_i$ be the $i^{th}$ column of $A$. If $\langle i |A^{\dagger} A |i \rangle = 0$, then
$$ \langle i |A^{\dagger}A| i\rangle = a_i^{\dagger} a_i = ||a_i||^2 = 0 \text{ iff } a_i = 0$$

Therefor $(A,A) = 0$ iff $A = 0$

ii).   A linear transformation $ T : ; \ V \rightarrow V$ where $\text{ dim }( V )= d$ can be represented as a $d \times d$ matrix. Since there are $d \times d = d^2$ matrices that are linearly independent, the dimension of $L_V$ is $d^2$.